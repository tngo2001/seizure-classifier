{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuroCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, checks, paths"
      ],
      "metadata": {
        "id": "kG_-2CWA7SRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports and checks\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "seizurePath = 'gdrive/MyDrive/SeizureCNN/'\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install mne\n",
        "import mne\n",
        "# for the nedc file\n",
        "!pip install pyedflib\n",
        "nedc = (seizurePath + 'nedc_pystream.py')\n",
        "import sys\n",
        "sys.path.insert(1, seizurePath)\n",
        "# file from the dataset\n",
        "from nedc_pystream import *\n",
        "import mne"
      ],
      "metadata": {
        "id": "1g5wGK-6jXXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# premade splits for training and validation provided by the dataset (for 5-fold cross validation)\n",
        "validationSplitsPickled = open('gdrive/MyDrive/SeizureCNN/cv_split_5_fold_seizure_wise_v1.5.2.pkl', 'rb')\n",
        "validationSplits = pickle.load(validationSplitsPickled)"
      ],
      "metadata": {
        "id": "9FL-aKzB4vta"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = ''\n",
        "test_path = '' \n",
        "valid_path = '' "
      ],
      "metadata": {
        "id": "vyXEiCqalEMp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing + splitting data "
      ],
      "metadata": {
        "id": "HR855lkAQIQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to get a sense of what the edf data looks like\n",
        "\n",
        "file = seizurePath + \"00000148_s001_t000.edf\"\n",
        "data = mne.io.read_raw_edf(file)\n",
        "raw_data = data.get_data()\n",
        "# you can get the metadata included in the file and a list of all channels:\n",
        "info = data.info\n",
        "channels = data.ch_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYb9cUGr2qDx",
        "outputId": "da64ae61-0d68-421d-845f-0a1551df3a6b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/gdrive/MyDrive/SeizureCNN/00000148_s001_t000.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this will go in the for loop when we figure out how to split in to smaller epochs\n",
        "# outputs a list (sample frequencies, signals, labels) each index in the list represents a channel\n",
        "# signals are the actual data \n",
        "fileData = nedc_load_edf(file) \n",
        "\n",
        "frequencies = fileData[0]\n",
        "signals = fileData[1]"
      ],
      "metadata": {
        "id": "ndtJ5KBjy9fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open one specific file  \n",
        "# using the .tse_bi file because it does not differentiate between different kinds of siezures\n",
        "with open(seizurePath + \"s002_2006_05_18/00002484_s002_t000.tse_bi\", \"r\", encoding='utf-8-sig') as f:\n",
        "    string = f.read()\n",
        "# timestamps \n",
        "string.splitlines()[2:]\n",
        "\n",
        "# tse format: start time in secs, stop time in secs, label, probability\n",
        "# output of above code: 2D list of tse event time stamps "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MveKMlXlW2W",
        "outputId": "9f0c47c8-f08f-47f8-d11b-fda66fbb2cd3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0.0000 660.9320 bckg 1.0000',\n",
              " '660.9320 800.0480 seiz 1.0000',\n",
              " '800.0480 1232.0000 bckg 1.0000']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for reference: to get the start, and stop times of seizures from the annotations \n",
        "def getTimeIndex(time, frequency):\n",
        "  return time * frequency"
      ],
      "metadata": {
        "id": "M5Er51NL945z"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- *code for splitting data into precise epochs will go here*"
      ],
      "metadata": {
        "id": "J_exL1_Ag5Jt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition\n"
      ],
      "metadata": {
        "id": "sScscok7lMJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# have to determine a good number of channels that is common to all data\n",
        "#and a protocol for replacing unavailable channels\n",
        "# 17 channels in commond between all 3 datasets\n",
        "num_channels = 17\n",
        "# time stamps per epoch (250 Hz * 10 seconds), most data is sampled at 250 Hz, so 2500 samples is usually 10 seconds\n",
        "input_shape = (num_channels, 2500)\n"
      ],
      "metadata": {
        "id": "CAs050E0nz0g"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv1D(16, 5, activation = 'relu', input_shape = input_shape))\n",
        "model.add(layers.Conv1D(32, 5, activation = 'relu', input_shape = input_shape))\n",
        "model.add(layers.MaxPool1D(\n",
        "    pool_size=2,\n",
        "    strides=None,\n",
        "    padding='valid',))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(32, activation = 'relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "9SPu9usnlLcf"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n"
      ],
      "metadata": {
        "id": "2AUNsZrDgcuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "id": "jTzf0a43hQxa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}